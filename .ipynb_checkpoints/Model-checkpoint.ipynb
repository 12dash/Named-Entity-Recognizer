{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Word Level/Sentence Tag idx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_file(path):\n",
    "    file = open(path,'rb')\n",
    "    a,b = pickle.load(file)\n",
    "    file.close()\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word,word2idx =fetch_file('Word Level/word_map.pkl')\n",
    "idx2tag,tag2idx = fetch_file('Word Level/tag_map.pkl')\n",
    "df['Word idx'] =df['Word idx'].apply(lambda x: ast.literal_eval(x))\n",
    "df['Tag idx'] =df['Tag idx'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Word idx'].to_list()\n",
    "Y = df['Tag idx'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d,X_test_d, y_train_d,y_test_d = train_test_split(X,Y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sen_len = max([len(i) for i in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = word2idx['PAD']*np.ones((len(X_train_d),max_sen_len))\n",
    "y_train = -1*np.ones((len(y_train_d), max_sen_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(X_train_d)):\n",
    "    sen_len = len(X_train_d[j])\n",
    "    temp_x = np.array(X_train_d[j])\n",
    "    temp_y = np.array(y_train_d[j])\n",
    "    X_train[j][:sen_len] = (temp_x)\n",
    "    y_train[j][:sen_len] = (temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = torch.LongTensor(X_train), torch.LongTensor(y_train)\n",
    "X_train, y_train = Variable(X_train), Variable(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,lstm_hidden_dim,number_of_tags):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_hidden_dim, batch_first = True)\n",
    "        self.fc= nn.Linear(lstm_hidden_dim, number_of_tags)\n",
    "    \n",
    "    def forward(self, s):\n",
    "        s = self.embedding(s)\n",
    "        s, _ = self.lstm(s)\n",
    "        s = s.view(-1, s.shape[2])\n",
    "        s = self.fc(s)\n",
    "        \n",
    "        return F.log_softmax(s, dim = 1)\n",
    "    \n",
    "    def loss_fn(output, labels):\n",
    "        labels = labels.view(-1)\n",
    "        mask = (labels >= 0).float()\n",
    "        num_tokens = int(torch.sum(mask).data[0])\n",
    "        outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
    "        \n",
    "        return -torch.sum(outputs)/num_tokens            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 128\n",
    "lstm_hidden_dim = 64\n",
    "num_tags = len(tag2idx)\n",
    "model = Net(vocab_size = vocab_size, embedding_dim = embedding_dim, lstm_hidden_dim = lstm_hidden_dim, number_of_tags = num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataset = []\n",
    "for i in range(len(X_train)):\n",
    "    data_dataset.append((X_train[i],y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train = torch.utils.data.DataLoader(data_dataset, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Data_train):\n",
    "        sent, labels = data\n",
    "        optimizer.zero_grad()        \n",
    "        output = model(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
